{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "336110d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/matthew.redmond@usfoods.com/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.decomposition import PCA\n",
    "import Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aeab3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Onion_NYT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6aacf89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Onion</th>\n",
       "      <th>Title</th>\n",
       "      <th>Published Time</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Misogyny Fuels Violence Against Women. Should ...</td>\n",
       "      <td>2021-03-26 00:31:15+00:00</td>\n",
       "      <td>Caroline Criado Perez, author of “Invisible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>‘No Time to Be a Child’</td>\n",
       "      <td>2021-09-25 18:58:22+00:00</td>\n",
       "      <td>A poem by Azariah Baker, a high school stude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>His, Hers, Everyone’s: Gender-Equal Underwear ...</td>\n",
       "      <td>2021-06-25 21:18:24+00:00</td>\n",
       "      <td>Abby Sugar, co-founder and chief executive o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A Fashion Show With an Unexpected Focus: Sexua...</td>\n",
       "      <td>2021-09-12 19:01:31+00:00</td>\n",
       "      <td>Amanda Nguyen, founder of the civil rights o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey, Alexa, Are You Sexist?</td>\n",
       "      <td>2021-02-12 21:20:20+00:00</td>\n",
       "      <td>Amazon’s Alexa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Onion                                              Title  \\\n",
       "0      0  Misogyny Fuels Violence Against Women. Should ...   \n",
       "1      0                            ‘No Time to Be a Child’   \n",
       "2      0  His, Hers, Everyone’s: Gender-Equal Underwear ...   \n",
       "3      0  A Fashion Show With an Unexpected Focus: Sexua...   \n",
       "4      0                        Hey, Alexa, Are You Sexist?   \n",
       "\n",
       "              Published Time  \\\n",
       "0  2021-03-26 00:31:15+00:00   \n",
       "1  2021-09-25 18:58:22+00:00   \n",
       "2  2021-06-25 21:18:24+00:00   \n",
       "3  2021-09-12 19:01:31+00:00   \n",
       "4  2021-02-12 21:20:20+00:00   \n",
       "\n",
       "                                             Content  \n",
       "0     Caroline Criado Perez, author of “Invisible...  \n",
       "1    A poem by Azariah Baker, a high school stude...  \n",
       "2    Abby Sugar, co-founder and chief executive o...  \n",
       "3    Amanda Nguyen, founder of the civil rights o...  \n",
       "4                                     Amazon’s Alexa  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f59d671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Content'] = df['Content'].str.replace(r'[^\\w\\s]+', '')\n",
    "#https://towardsdatascience.com/remove-punctuation-pandas-3e461efe9584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8af97845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Onion</th>\n",
       "      <th>Title</th>\n",
       "      <th>Published Time</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Misogyny Fuels Violence Against Women. Should ...</td>\n",
       "      <td>2021-03-26 00:31:15+00:00</td>\n",
       "      <td>Caroline Criado Perez author of Invisible W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>‘No Time to Be a Child’</td>\n",
       "      <td>2021-09-25 18:58:22+00:00</td>\n",
       "      <td>A poem by Azariah Baker a high school studen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>His, Hers, Everyone’s: Gender-Equal Underwear ...</td>\n",
       "      <td>2021-06-25 21:18:24+00:00</td>\n",
       "      <td>Abby Sugar cofounder and chief executive of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A Fashion Show With an Unexpected Focus: Sexua...</td>\n",
       "      <td>2021-09-12 19:01:31+00:00</td>\n",
       "      <td>Amanda Nguyen founder of the civil rights or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey, Alexa, Are You Sexist?</td>\n",
       "      <td>2021-02-12 21:20:20+00:00</td>\n",
       "      <td>Amazons Alexa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Onion                                              Title  \\\n",
       "0      0  Misogyny Fuels Violence Against Women. Should ...   \n",
       "1      0                            ‘No Time to Be a Child’   \n",
       "2      0  His, Hers, Everyone’s: Gender-Equal Underwear ...   \n",
       "3      0  A Fashion Show With an Unexpected Focus: Sexua...   \n",
       "4      0                        Hey, Alexa, Are You Sexist?   \n",
       "\n",
       "              Published Time  \\\n",
       "0  2021-03-26 00:31:15+00:00   \n",
       "1  2021-09-25 18:58:22+00:00   \n",
       "2  2021-06-25 21:18:24+00:00   \n",
       "3  2021-09-12 19:01:31+00:00   \n",
       "4  2021-02-12 21:20:20+00:00   \n",
       "\n",
       "                                             Content  \n",
       "0     Caroline Criado Perez author of Invisible W...  \n",
       "1    A poem by Azariah Baker a high school studen...  \n",
       "2    Abby Sugar cofounder and chief executive of ...  \n",
       "3    Amanda Nguyen founder of the civil rights or...  \n",
       "4                                      Amazons Alexa  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d84d8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Title_tk\"] = df[\"Title\"].apply(lambda x: nltk.word_tokenize(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "793c672b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Onion</th>\n",
       "      <th>Title</th>\n",
       "      <th>Published Time</th>\n",
       "      <th>Content</th>\n",
       "      <th>Title_tk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Misogyny Fuels Violence Against Women. Should ...</td>\n",
       "      <td>2021-03-26 00:31:15+00:00</td>\n",
       "      <td>Caroline Criado Perez author of Invisible W...</td>\n",
       "      <td>[Misogyny, Fuels, Violence, Against, Women, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>‘No Time to Be a Child’</td>\n",
       "      <td>2021-09-25 18:58:22+00:00</td>\n",
       "      <td>A poem by Azariah Baker a high school studen...</td>\n",
       "      <td>[‘, No, Time, to, Be, a, Child, ’]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>His, Hers, Everyone’s: Gender-Equal Underwear ...</td>\n",
       "      <td>2021-06-25 21:18:24+00:00</td>\n",
       "      <td>Abby Sugar cofounder and chief executive of ...</td>\n",
       "      <td>[His, ,, Hers, ,, Everyone, ’, s, :, Gender-Eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A Fashion Show With an Unexpected Focus: Sexua...</td>\n",
       "      <td>2021-09-12 19:01:31+00:00</td>\n",
       "      <td>Amanda Nguyen founder of the civil rights or...</td>\n",
       "      <td>[A, Fashion, Show, With, an, Unexpected, Focus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey, Alexa, Are You Sexist?</td>\n",
       "      <td>2021-02-12 21:20:20+00:00</td>\n",
       "      <td>Amazons Alexa</td>\n",
       "      <td>[Hey, ,, Alexa, ,, Are, You, Sexist, ?]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Onion                                              Title  \\\n",
       "0      0  Misogyny Fuels Violence Against Women. Should ...   \n",
       "1      0                            ‘No Time to Be a Child’   \n",
       "2      0  His, Hers, Everyone’s: Gender-Equal Underwear ...   \n",
       "3      0  A Fashion Show With an Unexpected Focus: Sexua...   \n",
       "4      0                        Hey, Alexa, Are You Sexist?   \n",
       "\n",
       "              Published Time  \\\n",
       "0  2021-03-26 00:31:15+00:00   \n",
       "1  2021-09-25 18:58:22+00:00   \n",
       "2  2021-06-25 21:18:24+00:00   \n",
       "3  2021-09-12 19:01:31+00:00   \n",
       "4  2021-02-12 21:20:20+00:00   \n",
       "\n",
       "                                             Content  \\\n",
       "0     Caroline Criado Perez author of Invisible W...   \n",
       "1    A poem by Azariah Baker a high school studen...   \n",
       "2    Abby Sugar cofounder and chief executive of ...   \n",
       "3    Amanda Nguyen founder of the civil rights or...   \n",
       "4                                      Amazons Alexa   \n",
       "\n",
       "                                            Title_tk  \n",
       "0  [Misogyny, Fuels, Violence, Against, Women, .,...  \n",
       "1                 [‘, No, Time, to, Be, a, Child, ’]  \n",
       "2  [His, ,, Hers, ,, Everyone, ’, s, :, Gender-Eq...  \n",
       "3  [A, Fashion, Show, With, an, Unexpected, Focus...  \n",
       "4            [Hey, ,, Alexa, ,, Are, You, Sexist, ?]  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3bdb3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Content_tk\"] = df[\"Content\"].apply(lambda x: nltk.word_tokenize(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "92f537d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmerl = LancasterStemmer()\n",
    "stemmerp = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "82e8fbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43461, 6)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10c8ae94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Onion</th>\n",
       "      <th>Title</th>\n",
       "      <th>Published Time</th>\n",
       "      <th>Content</th>\n",
       "      <th>Title_tk</th>\n",
       "      <th>Content_tk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FBI Sent Itemized Bill For 12-Hour Stay At Mar...</td>\n",
       "      <td>2022-08-12T10:30:00-05:00</td>\n",
       "      <td>PALM BEACH FLORIDA Faxing the government agenc...</td>\n",
       "      <td>[FBI, Sent, Itemized, Bill, For, 12-Hour, Stay...</td>\n",
       "      <td>[PALM, BEACH, FLORIDA, Faxing, the, government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Startling Evidence Finds Pentagon Failed To St...</td>\n",
       "      <td>2022-08-12T06:00:00-05:00</td>\n",
       "      <td>WASHINGTON Calling into question the Defense D...</td>\n",
       "      <td>[Startling, Evidence, Finds, Pentagon, Failed,...</td>\n",
       "      <td>[WASHINGTON, Calling, into, question, the, Def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Department Of Transportation Reduces Commute T...</td>\n",
       "      <td>2022-08-12T05:30:00-05:00</td>\n",
       "      <td>WASHINGTON Saying the infrastructure project w...</td>\n",
       "      <td>[Department, Of, Transportation, Reduces, Comm...</td>\n",
       "      <td>[WASHINGTON, Saying, the, infrastructure, proj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>FBI Turns Over Mar-A-Lago Documents To Dork Ag...</td>\n",
       "      <td>2022-08-11T13:30:00-05:00</td>\n",
       "      <td>WASHINGTON Following this weeks raid on former...</td>\n",
       "      <td>[FBI, Turns, Over, Mar-A-Lago, Documents, To, ...</td>\n",
       "      <td>[WASHINGTON, Following, this, weeks, raid, on,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Chicago Defends Relocating Polluting Factory T...</td>\n",
       "      <td>2022-08-11T06:15:00-05:00</td>\n",
       "      <td>CHICAGO In response to outcry among South Side...</td>\n",
       "      <td>[Chicago, Defends, Relocating, Polluting, Fact...</td>\n",
       "      <td>[CHICAGO, In, response, to, outcry, among, Sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Onion                                              Title  \\\n",
       "0      1  FBI Sent Itemized Bill For 12-Hour Stay At Mar...   \n",
       "1      1  Startling Evidence Finds Pentagon Failed To St...   \n",
       "2      1  Department Of Transportation Reduces Commute T...   \n",
       "3      1  FBI Turns Over Mar-A-Lago Documents To Dork Ag...   \n",
       "4      1  Chicago Defends Relocating Polluting Factory T...   \n",
       "\n",
       "              Published Time  \\\n",
       "0  2022-08-12T10:30:00-05:00   \n",
       "1  2022-08-12T06:00:00-05:00   \n",
       "2  2022-08-12T05:30:00-05:00   \n",
       "3  2022-08-11T13:30:00-05:00   \n",
       "4  2022-08-11T06:15:00-05:00   \n",
       "\n",
       "                                             Content  \\\n",
       "0  PALM BEACH FLORIDA Faxing the government agenc...   \n",
       "1  WASHINGTON Calling into question the Defense D...   \n",
       "2  WASHINGTON Saying the infrastructure project w...   \n",
       "3  WASHINGTON Following this weeks raid on former...   \n",
       "4  CHICAGO In response to outcry among South Side...   \n",
       "\n",
       "                                            Title_tk  \\\n",
       "0  [FBI, Sent, Itemized, Bill, For, 12-Hour, Stay...   \n",
       "1  [Startling, Evidence, Finds, Pentagon, Failed,...   \n",
       "2  [Department, Of, Transportation, Reduces, Comm...   \n",
       "3  [FBI, Turns, Over, Mar-A-Lago, Documents, To, ...   \n",
       "4  [Chicago, Defends, Relocating, Polluting, Fact...   \n",
       "\n",
       "                                          Content_tk  \n",
       "0  [PALM, BEACH, FLORIDA, Faxing, the, government...  \n",
       "1  [WASHINGTON, Calling, into, question, the, Def...  \n",
       "2  [WASHINGTON, Saying, the, infrastructure, proj...  \n",
       "3  [WASHINGTON, Following, this, weeks, raid, on,...  \n",
       "4  [CHICAGO, In, response, to, outcry, among, Sou...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0205eee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2729606\n"
     ]
    }
   ],
   "source": [
    "list_length = 0\n",
    "for x in df[\"Content_tk\"]:\n",
    "    list_length = list_length + len(x)\n",
    "print(list_length)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "504c4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "listforcv = []\n",
    "for x in df[\"Content\"]:\n",
    "    listforcv.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2e8de5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(listforcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4bf96181",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "X = cv.fit_transform(listforcv)\n",
    "df2 = pd.DataFrame(X.toarray(),columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "233d996b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Onion              int64\n",
       "Title             object\n",
       "Published Time    object\n",
       "Content           object\n",
       "Title_tk          object\n",
       "Content_tk        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab881bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['00', '00000000001', '0000000001ounce', '000000029', '0000001',\n",
       "       '000002', '000009', '000017935', '00003', '00005',\n",
       "       ...\n",
       "       'αamylase', '作者价值', '奈苗', '平台价值', '東京', '用户价值', '美苗', '长期', '閱讀繁體中文版',\n",
       "       '阅读简体中文版'],\n",
       "      dtype='object', length=84474)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2aba12f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmerl = LancasterStemmer()\n",
    "stemmerp = PorterStemmer()\n",
    "listforcvl = [[stemmerl.stem(word) for word in sentence.split(' ')] for sentence in listforcv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b20991bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "listforcvp = [[stemmerp.stem(word) for word in sentence.split(' ')] for sentence in listforcv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8201fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['   Caroline Criado Perez author of Invisible Women Exposing Data Bias in a World Designed for Men',\n",
       " '  A poem by Azariah Baker a high school student in Chicago',\n",
       " '  Abby Sugar cofounder and chief executive of Play Out Apparel',\n",
       " '  Amanda Nguyen founder of the civil rights organization Rise which hosted a fashion show at New York Fashion Week to celebrate survivors',\n",
       " '  Amazons Alexa',\n",
       " '  Amber Adler who ran for City Council in Brooklyns 48th district',\n",
       " '  Anna Sale the author of Lets Talk About Hard Things',\n",
       " '  Ava Thompson Greenwell the author of Ladies Leading The Black Women Who Control Television News',\n",
       " '  Brittney Cooper the author of Eloquent Rage and associate professor of womens and gender studies and Africana studies at Rutgers University',\n",
       " '  C Nicole Mason president and chief executive of the Institute for Womens Policy Research']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listforcv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "151ce952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['',\n",
       "  '',\n",
       "  '',\n",
       "  'carolin',\n",
       "  'criado',\n",
       "  'perez',\n",
       "  'auth',\n",
       "  'of',\n",
       "  'invis',\n",
       "  'wom',\n",
       "  'expos',\n",
       "  'dat',\n",
       "  'bia',\n",
       "  'in',\n",
       "  'a',\n",
       "  'world',\n",
       "  'design',\n",
       "  'for',\n",
       "  'men'],\n",
       " ['',\n",
       "  '',\n",
       "  'a',\n",
       "  'poem',\n",
       "  'by',\n",
       "  'azariah',\n",
       "  'bak',\n",
       "  'a',\n",
       "  'high',\n",
       "  'school',\n",
       "  'stud',\n",
       "  'in',\n",
       "  'chicago'],\n",
       " ['',\n",
       "  '',\n",
       "  'abby',\n",
       "  'sug',\n",
       "  'cofound',\n",
       "  'and',\n",
       "  'chief',\n",
       "  'execut',\n",
       "  'of',\n",
       "  'play',\n",
       "  'out',\n",
       "  'apparel'],\n",
       " ['',\n",
       "  '',\n",
       "  'amand',\n",
       "  'nguy',\n",
       "  'found',\n",
       "  'of',\n",
       "  'the',\n",
       "  'civil',\n",
       "  'right',\n",
       "  'org',\n",
       "  'ris',\n",
       "  'which',\n",
       "  'host',\n",
       "  'a',\n",
       "  'fash',\n",
       "  'show',\n",
       "  'at',\n",
       "  'new',\n",
       "  'york',\n",
       "  'fash',\n",
       "  'week',\n",
       "  'to',\n",
       "  'celebr',\n",
       "  'surv'],\n",
       " ['', '', 'amazon', 'alex'],\n",
       " ['',\n",
       "  '',\n",
       "  'amb',\n",
       "  'adl',\n",
       "  'who',\n",
       "  'ran',\n",
       "  'for',\n",
       "  'city',\n",
       "  'council',\n",
       "  'in',\n",
       "  'brooklyn',\n",
       "  '48th',\n",
       "  'district'],\n",
       " ['',\n",
       "  '',\n",
       "  'ann',\n",
       "  'sal',\n",
       "  'the',\n",
       "  'auth',\n",
       "  'of',\n",
       "  'let',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'hard',\n",
       "  'thing'],\n",
       " ['',\n",
       "  '',\n",
       "  'av',\n",
       "  'thompson',\n",
       "  'greenwel',\n",
       "  'the',\n",
       "  'auth',\n",
       "  'of',\n",
       "  'lady',\n",
       "  'lead',\n",
       "  'the',\n",
       "  'black',\n",
       "  'wom',\n",
       "  'who',\n",
       "  'control',\n",
       "  'televid',\n",
       "  'new'],\n",
       " ['',\n",
       "  '',\n",
       "  'brittney',\n",
       "  'coop',\n",
       "  'the',\n",
       "  'auth',\n",
       "  'of',\n",
       "  'eloqu',\n",
       "  'rag',\n",
       "  'and',\n",
       "  'assocy',\n",
       "  'profess',\n",
       "  'of',\n",
       "  'wom',\n",
       "  'and',\n",
       "  'gend',\n",
       "  'study',\n",
       "  'and',\n",
       "  'african',\n",
       "  'study',\n",
       "  'at',\n",
       "  'rutg',\n",
       "  'univers'],\n",
       " ['',\n",
       "  '',\n",
       "  'c',\n",
       "  'nicol',\n",
       "  'mason',\n",
       "  'presid',\n",
       "  'and',\n",
       "  'chief',\n",
       "  'execut',\n",
       "  'of',\n",
       "  'the',\n",
       "  'institut',\n",
       "  'for',\n",
       "  'wom',\n",
       "  'policy',\n",
       "  'research']]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listforcvl[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6308f580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew.redmond@usfoods.com/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'aft', 'afterward', 'al', 'alon', 'alway', 'anoth', 'anyon', 'anyth', 'anywh', 'ar', 'becam', 'becaus', 'becom', 'bef', 'besid', 'bil', 'cal', 'describ', 'don', 'dur', 'eith', 'elev', 'els', 'elsewh', 'ev', 'everyon', 'everyth', 'everywh', 'exceiv', 'fil', 'fir', 'fiv', 'form', 'ful', 'furth', 'giv', 'hav', 'hent', 'hereaft', 'howev', 'hundr', 'indee', 'int', 'lat', 'mad', 'meanwhil', 'mil', 'min', 'mor', 'moreov', 'mov', 'nam', 'neith', 'nev', 'nin', 'non', 'noon', 'noth', 'nowh', 'oft', 'ont', 'oth', 'otherw', 'ourselv', 'ov', 'perhap', 'pleas', 'rath', 'sam', 'sery', 'sev', 'sid', 'sint', 'som', 'someon', 'someth', 'sometim', 'somewh', 'stil', 'tak', 'themselv', 'thent', 'ther', 'thereaft', 'theref', 'thes', 'thi', 'thos', 'thu', 'togeth', 'twelv', 'und', 'wel', 'wer', 'whatev', 'whenev', 'whent', 'wher', 'wherea', 'whereaft', 'wherev', 'wheth', 'whil', 'whith', 'whoev', 'whol', 'whos', 'wil', 'yo', 'yourselv'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['00', '00000000001', '0000000001ounce', '000000029', '0000001',\n",
       "       '000002', '000009', '000017935', '00003', '00005',\n",
       "       ...\n",
       "       'αamylase', '作者价值', '奈苗', '平台价值', '東京', '用户价值', '美苗', '长期', '閱讀繁體中文版',\n",
       "       '阅读简体中文版'],\n",
       "      dtype='object', length=85188)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english',\n",
    "                      min_df=1,  # This is default; this is just a reminder it exists\n",
    "                      max_df=0.8,\n",
    "                      preprocessor=prep)\n",
    "X = cv.fit_transform(listforcv)\n",
    "df2 = pd.DataFrame(X.toarray(),columns=cv.get_feature_names())\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dd075da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(word, stemmer=LancasterStemmer()):\n",
    "    \n",
    "        \n",
    "    if stemmer is None:\n",
    "        return word.lower()\n",
    "    \n",
    "    else:\n",
    "        return stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "31633a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/27673527/how-should-i-vectorize-the-following-list-of-lists-with-scikit-learn\n",
    "corpus = [[\"this is spam, 'SPAM'\"],[\"this is ham, 'HAM'\"],[\"this is nothing, 'NOTHING'\"]]\n",
    "\n",
    "bag_of_words = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False).fit_transform(splited_labels_from_corpus)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "17944da7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-69209a8b2b27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;31m# Get variance explained by singular values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mtotal_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvar\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m   3619\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3621\u001b[0;31m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0m\u001b[1;32m   3622\u001b[0m                          **kwargs)\n\u001b[1;32m   3623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 5)\n",
    "pca.fit(df2)\n",
    "pca.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca24f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (unsupervised)",
   "language": "python",
   "name": "unsupervised"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
